"""
Performance Visualization for Higher Order Jacobi Method (HOJM) Benchmarks

This module generates publication-quality performance comparison plots from the timing
data collected by the benchmarking suite. It creates log-log scale plots that clearly
show the computational complexity scaling and relative performance of different methods.

The visualization includes:
- Linear system solving performance comparison
- Matrix inversion performance comparison
- Color-coded and styled plots for different methods
- Automatic scaling and formatting for publication use

The plots help identify:
- Computational complexity trends (slope analysis)
- Performance crossover points between methods
- Relative efficiency of HOJM vs traditional methods
- Hardware acceleration benefits (CPU vs GPU)

Author: Nithin Kumar Goona, Ph.D.
Affiliation: The University of Texas at El Paso (UTEP)
Created on: July 29, 2025

Description:
    Visualization tool for HOJM performance benchmarks that:
    - Loads timing data from pickle files generated by comparison benchmarks
    - Creates log-log scale performance plots with professional styling
    - Generates separate plots for solving and inversion operations
    - Uses consistent color schemes and line styles for method identification
    - Saves high-resolution plots suitable for publication
    
    Input: Pickle files containing timing data from comparision_of_computation_times.py
    Output: High-resolution PNG plots showing performance comparisons

License:
    MIT

Contact:
    nkgoona@utep.edu, nithin.goona@gmail.com
"""

import matplotlib.pyplot as plt
import pickle
import os
import numpy as np

plt.rcParams['font.family'] = 'PT Sans'


def estimate_complexity(non, times):
    """
    Estimate computational complexity from timing data using power law fitting.
    
    This function analyzes the scaling behavior of algorithms by fitting a power law
    of the form T(n) = C * n^p to the timing data, where:
    - T(n) is the execution time for problem size n
    - C is a constant factor
    - p is the complexity exponent
    
    The complexity exponent p indicates:
    - p ≈ 1: Linear complexity O(n)
    - p ≈ 2: Quadratic complexity O(n²)  
    - p ≈ 3: Cubic complexity O(n³)
    
    Args:
        non (list): Problem sizes (number of unknowns)
        times (list): Corresponding execution times
        
    Returns:
        tuple: (C, p) where:
            - C (float): Constant factor in T(n) = C * n^p
            - p (float): Complexity exponent
            
    Note:
        Uses the last two data points for robust estimation.
        Assumes power law scaling T(n) = C * n^p.
    """
    # Use last two data points for complexity estimation
    n1, n2 = non[-2], non[-1]  # Problem sizes
    t1, t2 = times[-2], times[-1]  # Corresponding times
    
    # Estimate complexity exponent: p = log(t2/t1) / log(n2/n1)
    p = (np.log(t2/t1)) / (np.log(n2/n1))
    
    # Estimate constant factor: C = t1 / n1^p
    C = t1 / (n1**p)
    
    return C, p


def main():
    """
    Main function that generates performance comparison plots for HOJM benchmarks.
    
    This function creates publication-quality log-log scale plots comparing the
    performance of different linear algebra methods. It processes timing data
    from benchmark runs and generates separate plots for:
    1. Linear system solving performance (Ax = b)
    2. Matrix inversion performance (A^-1)
    
    The plots use consistent styling, colors, and formatting to clearly show
    performance differences and computational complexity scaling across methods.
    """
    
    # ============================================================================
    # 0. PLOT CONFIGURATION AND DATA LOADING
    # ============================================================================
    
    # Configuration parameters
    precision = "32"        # Floating point precision used in benchmarks
    order = 4              # Starting matrix size order (2^order x 2^order grid)
    save_dir = "results"   # Directory containing benchmark results
    
    # Set high-quality plot parameters for publication
    plt.rcParams.update({
        'font.size': 18,      # Large font for readability
        'figure.dpi': 600     # High resolution for publication quality
    })

    # Load timing data from benchmark results
    filename = f"solve_times_precision_{precision}.pkl"
    save_path = os.path.join(save_dir, filename)
    
    print(f"Loading benchmark data from: {save_path}")
    times = pickle.load(open(save_path, "rb"))  # Load timing results dictionary

    # ============================================================================
    # 1. VISUAL STYLING CONFIGURATION
    # ============================================================================
    
    # Define color palette for different method categories
    purple = "#cf70d6"      # SciPy sparse methods
    teal = "#13b199"        # PyTorch linear algebra methods
    gold = "#a0aa14"        # HOJM training phases
    red = '#e02b35'         # NumPy dense methods
    light_blue = "#249fe0"  # HOJM inference phases

    # Color mapping for each benchmarked method
    # Groups methods by type for visual consistency
    colors = {
        'numpy': red,                    # NumPy dense linear algebra
        'scipy': purple,                 # SciPy sparse linear algebra
        'torch_linalg_cpu': teal,        # PyTorch CPU linear algebra
        'torch_linalg_gpu': teal,        # PyTorch GPU linear algebra
        'torch_hojm_cpu_while': gold,    # HOJM CPU training phase
        'torch_hojm_cpu_after': light_blue,  # HOJM CPU inference phase
        'torch_hojm_gpu_while': gold,    # HOJM GPU training phase
        'torch_hojm_gpu_after': light_blue,  # HOJM GPU inference phase
        'torch_hojm_cpu': gold,          # HOJM CPU complete inversion
        'torch_hojm_gpu': gold,          # HOJM GPU complete inversion
    }

    # Line style mapping to distinguish CPU vs GPU implementations
    # Solid lines for CPU, dashed lines for GPU
    linestyles = {
        'numpy': '-',                    # Solid (CPU only)
        'scipy': '-',                    # Solid (CPU only)
        'torch_linalg_cpu': '-',         # Solid (CPU)
        'torch_linalg_gpu': '--',        # Dashed (GPU)
        'torch_hojm_cpu_while': '-',     # Solid (CPU)
        'torch_hojm_cpu_after': '-',     # Solid (CPU)
        'torch_hojm_gpu_while': '--',    # Dashed (GPU)
        'torch_hojm_gpu_after': '--',    # Dashed (GPU)
        'torch_hojm_cpu': '-',           # Solid (CPU)
        'torch_hojm_gpu': '--',          # Dashed (GPU)
    }

    # ============================================================================
    # 2. LINEAR SYSTEM SOLVING PERFORMANCE PLOT (Ax = b)
    # ============================================================================
    
    print("Generating linear system solving performance plot...")
    
    # Determine maximum number of data points across all methods
    max_len = 0
    for _, value in times["solve"].items():
        if len(value) > max_len:
            max_len = len(value)

    # Generate matrix sizes corresponding to benchmark data points
    # Matrix size grows as powers of 2: 2^4, 2^5, 2^6, etc.
    non = []  # Number of unknowns (matrix size)
    for i in range(max_len):
        current_order = order + i  # Current power of 2
        ny = 32                   # Fixed y-dimension
        nx = 2**current_order    # x-dimension grows exponentially
        nt = nx * ny             # Total matrix size (number of unknowns)
        non.append(nt)

    # Create figure with publication-quality dimensions
    solve_fig = plt.figure(figsize=(10, 6))
    ax = solve_fig.add_subplot(1, 1, 1)

    # Plot performance curves for each benchmarked method
    for key, values in times["solve"].items():
        ax.plot(non[:len(values)], values,
                label=key.replace('_', ' '),           # Clean up method names for legend
                color=colors.get(key, 'black'),        # Use predefined colors
                linestyle=linestyles.get(key, '-'),    # Use predefined line styles
                marker='o')                            # Add markers for data points

    # Configure log-log scale plot for complexity analysis
    ax.set_xscale("log")    # Logarithmic x-axis (matrix size)
    ax.set_yscale("log")    # Logarithmic y-axis (execution time)
    
    # Set axis labels and title
    ax.set_xlabel("log(Size of Matrix)")
    ax.set_ylabel("log(Solve Time) (seconds)")
    ax.set_title("Solver Performance Comparison")
    
    # Configure legend and grid
    ax.legend(loc='lower right')  # Position legend to avoid data overlap
    ax.grid(True)                 # Add grid for easier reading
    
    # Set axis limits for optimal visualization
    plt.xlim(4e2, 2e5)     # x-axis limits: 400 to 200,000 unknowns
    plt.ylim(3e-4, 3e2)    # y-axis limits: 0.3ms to 300s
    
    # Finalize and save the plot
    plt.tight_layout()     # Optimize spacing
    solve_plot_filename = f"solve_times_plot_precision_{precision}.png"
    plt.savefig(solve_plot_filename)
    plt.close()           # Free memory
    
    print(f"Linear system solving plot saved as: {solve_plot_filename}")


    # ============================================================================
    # 3. MATRIX INVERSION PERFORMANCE PLOT (A^-1)
    # ============================================================================
    
    print("Generating matrix inversion performance plot...")
    
    # Determine maximum number of data points across all inversion methods
    max_len = 0
    for _, value in times["inverse"].items():
        if len(value) > max_len:
            max_len = len(value)

    # Generate matrix sizes corresponding to benchmark data points
    # Same scaling as solve benchmarks for consistency
    non = []  # Number of unknowns (matrix size)
    for i in range(max_len):
        current_order = order + i  # Current power of 2
        ny = 32                   # Fixed y-dimension
        nx = 2**current_order    # x-dimension grows exponentially
        nt = nx * ny             # Total matrix size (number of unknowns)
        non.append(nt)

    # Create figure with publication-quality dimensions
    inverse_fig = plt.figure(figsize=(10, 6))
    ax = inverse_fig.add_subplot(1, 1, 1)

    # Plot performance curves for each benchmarked inversion method
    for key, values in times["inverse"].items():
        ax.plot(non[:len(values)], values,
                label=key.replace('_', ' '),           # Clean up method names for legend
                color=colors.get(key, 'black'),        # Use predefined colors
                linestyle=linestyles.get(key, '-'),    # Use predefined line styles
                marker='o')                            # Add markers for data points

    # Configure log-log scale plot for complexity analysis
    ax.set_xscale("log")    # Logarithmic x-axis (matrix size)
    ax.set_yscale("log")    # Logarithmic y-axis (execution time)
    
    # Set axis labels and title
    ax.set_xlabel("log(Size of Matrix)")
    ax.set_ylabel("log(Inversion Time) (seconds)")
    ax.set_title("Inverse Performance Comparison")
    
    # Configure legend and grid
    ax.legend(loc='lower right')  # Position legend to avoid data overlap
    ax.grid(True)                 # Add grid for easier reading
    
    # Set axis limits optimized for inversion data
    # Note: Inversion is more computationally expensive, so smaller max size
    plt.xlim(4e2, 5e4)     # x-axis limits: 400 to 50,000 unknowns
    plt.ylim(6e-4, 2e2)    # y-axis limits: 0.6ms to 200s
    
    # Finalize and save the plot
    plt.tight_layout()     # Optimize spacing
    inverse_plot_filename = f"inverse_times_plot_precision_{precision}.png"
    plt.savefig(inverse_plot_filename)
    plt.close()           # Free memory
    
    print(f"Matrix inversion plot saved as: {inverse_plot_filename}")
    
    # ============================================================================
    # 4. COMPLETION SUMMARY
    # ============================================================================
    
    print("\nPlot generation completed successfully!")
    print("Generated plots:")
    print(f"  - Linear system solving: {solve_plot_filename}")
    print(f"  - Matrix inversion: {inverse_plot_filename}")
    print("\nPlots show performance scaling on log-log scale.")
    print("Slope of lines indicates computational complexity:")
    print("  - Slope ≈ 1: O(n) linear complexity")
    print("  - Slope ≈ 2: O(n²) quadratic complexity") 
    print("  - Slope ≈ 3: O(n³) cubic complexity")



if __name__ == '__main__':
    main()